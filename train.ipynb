{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "CONFIG = {\n",
    "    'SEED': 42,\n",
    "    'BATCH_SIZE': 16,\n",
    "    'SUBMISSION_NUMBER': 2\n",
    "}\n",
    "\n",
    "seed_everything(CONFIG['SEED']) # Seed 고정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                sentence type polarity tense  \\\n0                  0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형       긍정    현재   \n1      이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...  사실형       긍정    과거   \n2      정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...  사실형       긍정    미래   \n3      서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...  사실형       긍정    과거   \n4               익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.  사실형       긍정    현재   \n...                                                  ...  ...      ...   ...   \n16536  ＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...  사실형       긍정    과거   \n16537  수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...  사실형       긍정    과거   \n16538  김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...  사실형       긍정    과거   \n16539  1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...  사실형       긍정    과거   \n16540                                      《목민심서》의 내용이다.  사실형       긍정    현재   \n\n      certainty  \n0            확실  \n1            확실  \n2            확실  \n3            확실  \n4            확실  \n...         ...  \n16536        확실  \n16537        확실  \n16538        확실  \n16539       불확실  \n16540        확실  \n\n[16541 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>type</th>\n      <th>polarity</th>\n      <th>tense</th>\n      <th>certainty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>미래</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16536</th>\n      <td>＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>16537</th>\n      <td>수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>16538</th>\n      <td>김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>16539</th>\n      <td>1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>불확실</td>\n    </tr>\n    <tr>\n      <th>16540</th>\n      <td>《목민심서》의 내용이다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n    </tr>\n  </tbody>\n</table>\n<p>16541 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['ID', 'label'], axis=1)\n",
    "train.columns = ['sentence', 'type', 'polarity', 'tense', 'certainty']\n",
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               sentence\n0     장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...\n1              조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.\n2           지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.\n3     수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...\n4     결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...\n...                                                 ...\n7085  2020 세계국가편람 모바일 앱은 세계 216개국의 국가개황과 주요 경제지표, 사회...\n7086                              탈세계화 징후들이 반갑지 않은 이유다.\n7087  틱톡은 6월 ＇인터넷 안전의 달＇을 맞아 올바른 개인정보 보호 관리 방법, 앱 내 ...\n7088  만약 3개월 간 채굴자들의 투표를 거쳐 2/3 이상의 해시파워가 ＇채굴세＇ 도입에 ...\n7089                        아버지 홍언필이 인기척에 깨 그 광경을 지켜봤다.\n\n[7090 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7085</th>\n      <td>2020 세계국가편람 모바일 앱은 세계 216개국의 국가개황과 주요 경제지표, 사회...</td>\n    </tr>\n    <tr>\n      <th>7086</th>\n      <td>탈세계화 징후들이 반갑지 않은 이유다.</td>\n    </tr>\n    <tr>\n      <th>7087</th>\n      <td>틱톡은 6월 ＇인터넷 안전의 달＇을 맞아 올바른 개인정보 보호 관리 방법, 앱 내 ...</td>\n    </tr>\n    <tr>\n      <th>7088</th>\n      <td>만약 3개월 간 채굴자들의 투표를 거쳐 2/3 이상의 해시파워가 ＇채굴세＇ 도입에 ...</td>\n    </tr>\n    <tr>\n      <th>7089</th>\n      <td>아버지 홍언필이 인기척에 깨 그 광경을 지켜봤다.</td>\n    </tr>\n  </tbody>\n</table>\n<p>7090 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop(['ID'], axis=1)\n",
    "test.columns = ['sentence']\n",
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                sentence  type  polarity  \\\n0                  0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.     1         0   \n1      이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...     1         0   \n2      정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...     1         0   \n3      서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...     1         0   \n4               익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.     1         0   \n...                                                  ...   ...       ...   \n16536  ＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...     1         0   \n16537  수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...     1         0   \n16538  김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...     1         0   \n16539  1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...     1         0   \n16540                                      《목민심서》의 내용이다.     1         0   \n\n       tense  certainty  \n0          2          1  \n1          0          1  \n2          1          1  \n3          0          1  \n4          2          1  \n...      ...        ...  \n16536      0          1  \n16537      0          1  \n16538      0          1  \n16539      0          0  \n16540      2          1  \n\n[16541 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>type</th>\n      <th>polarity</th>\n      <th>tense</th>\n      <th>certainty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16536</th>\n      <td>＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16537</th>\n      <td>수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16538</th>\n      <td>김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16539</th>\n      <td>1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16540</th>\n      <td>《목민심서》의 내용이다.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>16541 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 2. Label Encoding (유형, 극성, 시제, 확실성)\n",
    "type_le = LabelEncoder()\n",
    "train[\"type\"] = type_le.fit_transform(train[\"type\"].values)\n",
    "\n",
    "polarity_le = LabelEncoder()\n",
    "train[\"polarity\"] = polarity_le.fit_transform(train[\"polarity\"].values)\n",
    "\n",
    "tense_le = LabelEncoder()\n",
    "train[\"tense\"] = tense_le.fit_transform(train[\"tense\"].values)\n",
    "\n",
    "certainty_le = LabelEncoder()\n",
    "train[\"certainty\"] = certainty_le.fit_transform(train[\"certainty\"].values)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from data_module import RoBertaDataModule\n",
    "\n",
    "dm = RoBertaDataModule(tokenizer=tokenizer, train_df=train, predict_df=test, batch_size=CONFIG['BATCH_SIZE'], max_token_len=512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from model import RoBERTa\n",
    "\n",
    "roberta = RoBERTa()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mkevan\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.13.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb/run-20221219_143649-20x954tc</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/kevan/sentense_classification/runs/20x954tc\" target=\"_blank\">daily-grass-6</a></strong> to <a href=\"https://wandb.ai/kevan/sentense_classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# make directory if it's not exists\n",
    "if not os.path.exists('ckpts'):\n",
    "    os.mkdir('ckpts')\n",
    "\n",
    "trainer_config = {\n",
    "    'max_epochs': 10,\n",
    "    'accelerator': 'auto',\n",
    "    'precision': 16,\n",
    "    'amp_backend': 'apex',\n",
    "    'callbacks': [\n",
    "        ModelCheckpoint(\n",
    "            dirpath='ckpts',\n",
    "            filename='{epoch:02d}-{val/loss-total:.3f}',\n",
    "            verbose=True,\n",
    "            save_last=True,\n",
    "            save_top_k=5,\n",
    "            monitor='val/loss-total',\n",
    "            mode='min'\n",
    "        ),\n",
    "        EarlyStopping(monitor='val/loss-total', min_delta=0.00, patience=2, verbose=True, mode='min'),\n",
    "    ],\n",
    "    'logger': WandbLogger(project=\"sentense_classification\")\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit apex Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(**trainer_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                 | Type         | Params\n",
      "------------------------------------------------------\n",
      "0 | roberta              | RobertaModel | 124 M \n",
      "1 | type_classifier      | Linear       | 3.1 K \n",
      "2 | polarity_classifier  | Linear       | 2.3 K \n",
      "3 | tense_classifier     | Linear       | 2.3 K \n",
      "4 | certainty_classifier | Linear       | 1.5 K \n",
      "------------------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "498.619   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "616f6737dff149e8b5a6f10d0815ebe8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42aab2ac812b4aefb2d1bb9ec9d34b9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc4f56e7d14646fb833a38bd1d4ac977"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss-total improved. New best score: 0.318\n",
      "Epoch 0, global step 827: 'val/loss-total' reached 0.31768 (best 0.31768), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=00-val/loss-total=0.318.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aba7913102ba4af595249c8331c945c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss-total improved by 0.040 >= min_delta = 0.0. New best score: 0.278\n",
      "Epoch 1, global step 1654: 'val/loss-total' reached 0.27776 (best 0.27776), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=01-val/loss-total=0.278.ckpt' as top 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "699a3c790d6245cca6dc45e463d76653"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss-total improved by 0.011 >= min_delta = 0.0. New best score: 0.267\n",
      "Epoch 2, global step 2481: 'val/loss-total' reached 0.26655 (best 0.26655), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=02-val/loss-total=0.267.ckpt' as top 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4cd1b82f0494b559d8cc116eaf7f877"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss-total improved by 0.007 >= min_delta = 0.0. New best score: 0.259\n",
      "Epoch 3, global step 3308: 'val/loss-total' reached 0.25935 (best 0.25935), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=03-val/loss-total=0.259.ckpt' as top 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f95abcad34c464e9382ba092ad3878f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss-total improved by 0.006 >= min_delta = 0.0. New best score: 0.253\n",
      "Epoch 4, global step 4135: 'val/loss-total' reached 0.25327 (best 0.25327), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=04-val/loss-total=0.253.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4bb0f31951364b538b34888b2ecd8025"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 4962: 'val/loss-total' reached 0.25475 (best 0.25327), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=05-val/loss-total=0.255.ckpt' as top 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6610759de84641c19d52075888933716"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss-total improved by 0.004 >= min_delta = 0.0. New best score: 0.249\n",
      "Epoch 6, global step 5789: 'val/loss-total' reached 0.24923 (best 0.24923), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=06-val/loss-total=0.249.ckpt' as top 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b40034db037a4d41972f80ba6bf0f26b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 6616: 'val/loss-total' reached 0.25066 (best 0.24923), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=07-val/loss-total=0.251.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e1d5af1222b443891dc9fc4b1996362"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss-total did not improve in the last 2 records. Best score: 0.249. Signaling Trainer to stop.\n",
      "Epoch 8, global step 7443: 'val/loss-total' reached 0.25440 (best 0.24923), saving model to '/home/fourind/projects/sentense_clf/ckpts/epoch=08-val/loss-total=0.254.ckpt' as top 5\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(roberta, dm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/fourind/projects/sentense_clf/ckpts/epoch=06-val/loss-total=0.249.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/fourind/projects/sentense_clf/ckpts/epoch=06-val/loss-total=0.249.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 827it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a51825560c99471387e7fa51f792d642"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = trainer.predict(roberta, dm, ckpt_path='best')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "preds = pd.DataFrame()\n",
    "for k in ['type', 'polarity', 'tense', 'certainty']:\n",
    "    logit = torch.concat([o[k] for o in output], dim=0)\n",
    "    _, preds[k] = torch.max(F.softmax(logit), 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# decoding\n",
    "preds[\"type\"] = type_le.inverse_transform(preds[\"type\"].values)\n",
    "preds[\"polarity\"] = polarity_le.inverse_transform(preds[\"polarity\"].values)\n",
    "preds[\"tense\"] = tense_le.inverse_transform(preds[\"tense\"].values)\n",
    "preds[\"certainty\"] = certainty_le.inverse_transform(preds[\"certainty\"].values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# combine preds\n",
    "preds['label'] = ['-'.join([row['type'],\n",
    "                            row['polarity'],\n",
    "                            row['tense'],\n",
    "                            row['certainty']]) for i, row in preds.iterrows()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# make submission csv\n",
    "submission['label'] = preds['label']\n",
    "submission.to_csv('submissions/submission_1.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
